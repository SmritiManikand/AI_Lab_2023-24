# Ex.No: 10 Learning â€“ Use Supervised Learning  
### DATE: 22.04.2024                                                                           
### REGISTER NUMBER : 212221040157
### AIM: 
To write a python program to train a model to perform sentiment analysis on social media data using machine learning techniques.

###  Algorithm:

1. Collect a dataset of social media posts with labeled sentiment (positive, negative).

2. Tokenize each social media post into individual words.

3. Represent each social media post as a feature vector using the presence of words as features.

4. Split the dataset into training and testing sets.

5. Train a machine learning classifier (e.g., Naive Bayes) on the labeled training dataset.

6. Evaluate the trained classifier's accuracy on the testing dataset.

### Program:

```
pip install nltk

import nltk
import random
from nltk.corpus import twitter_samples
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk import classify
from nltk import NaiveBayesClassifier

# Download NLTK resources (if not already downloaded)
nltk.download('twitter_samples')
nltk.download('punkt')
nltk.download('stopwords')

# Load positive and negative tweets dataset from NLTK
positive_tweets = twitter_samples.strings('positive_tweets.json')
negative_tweets = twitter_samples.strings('negative_tweets.json')

# Tokenization, stopword removal, and stemming
stop_words = set(stopwords.words('english'))
stemmer = PorterStemmer()

def preprocess(tweet):
    tokens = word_tokenize(tweet)
    clean_tokens = [stemmer.stem(token.lower()) for token in tokens if token.lower() not in stop_words and token.isalnum()]
    return dict([token, True] for token in clean_tokens)

# Preprocess positive and negative tweets
positive_tweets_processed = [(preprocess(tweet), 'Positive') for tweet in positive_tweets]
negative_tweets_processed = [(preprocess(tweet), 'Negative') for tweet in negative_tweets]

# Combine positive and negative tweets, shuffle them, and split into training and testing sets
dataset = positive_tweets_processed + negative_tweets_processed
random.shuffle(dataset)
train_data = dataset[:7000]
test_data = dataset[7000:]

# Train Naive Bayes classifier
classifier = NaiveBayesClassifier.train(train_data)

# Evaluate classifier accuracy
accuracy = classify.accuracy(classifier, test_data)
print("Accuracy:", accuracy)

# Example usage: classify a new tweet
new_tweet = "I love this product!"
preprocessed_tweet = preprocess(new_tweet)
sentiment = classifier.classify(preprocessed_tweet)
print("Sentiment:", sentiment)

```

### Output:

[nltk_data] Downloading package twitter_samples to /root/nltk_data...
[nltk_data]   Package twitter_samples is already up-to-date!
[nltk_data] Downloading package punkt to /root/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
Accuracy: 0.7503333333333333
Sentiment: Positive


### Result:
Thus the system was trained successfully and the prediction was carried out.
